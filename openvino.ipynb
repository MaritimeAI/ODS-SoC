{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "openvino.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OsIJiRBJgt0"
      },
      "source": [
        "# Dependencies\n",
        "\n",
        "Use extra UbuntuGIS repository to get _GDAL_ version 3.0.4 or higher, since _Colab_'s native version 2.2.x is too old for the pipeline.\n",
        "\n",
        "> If after installation version of _GDAL_ at the end is still 2.2.x, then restart runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U6xe5p7Jb06"
      },
      "source": [
        "# Check container OS version (for correct UbuntuGIS package version)\n",
        "!lsb_release -a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj6yD3COJgOB"
      },
      "source": [
        "## GDAL\n",
        "\n",
        "> If _GDAL 3.0.4_ (library and _Python_ bindings) or above is already installed in the system, then just skip or comment out the cell below, 'cause it's intended for _Google Colab_, which has _GDAL 2.2.x_ only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wMhAvbXJct9"
      },
      "source": [
        "# Dark magic happens here: installing dependencies for GDAL 3.0.4\n",
        "# build process via APT and install GDAL itself via PyPI\n",
        "!time (add-apt-repository -y ppa:ubuntugis/ubuntugis-unstable && \\\n",
        " apt install python3-gdal=3.0.4+dfsg-1~bionic0 && \\\n",
        " apt purge --autoremove python3-gdal && \\\n",
        " pip install gdal==3.0.4 && \\\n",
        " apt install gdal-bin=3.0.4+dfsg-1~bionic0)\n",
        "\n",
        "from osgeo import gdal; print(f\"\\nGDAL version {(gdal.__version__)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KJoxvtAfNel"
      },
      "source": [
        "## OpenVINO\n",
        "\n",
        "Install Intel Â® OpenVINO\n",
        "\n",
        "> OpenVINO DLDT will be accessible as `import openvino`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtXjuBcXiHkQ"
      },
      "source": [
        "%pip install -q openvino-dev[onnx]\n",
        "\n",
        "!mo -h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9LSMTirrmnQ"
      },
      "source": [
        "# Google Drive\n",
        "\n",
        "Mount _Google Drive_ for SAR images (recomended to store input and output images).\n",
        "\n",
        "> If _Google Colab_ is not used, then this cell may be commented out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMjcPgikrRfs"
      },
      "source": [
        "from os import path as osp\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "PATH_DRIVE = osp.join('/', 'content', 'drive')\n",
        "\n",
        "# Do not mount if it is already attached\n",
        "if not osp.exists(PATH_DRIVE):\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    drive.mount(PATH_DRIVE)\n",
        "else:\n",
        "    print(\"Google Drive has been already mounted!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lKJNKdQryv1"
      },
      "source": [
        "# Paths\n",
        "\n",
        "Paths to be used by preprocessing steps. Use `PATH_STORAGE` as a subdirectory hierarchy to store processed GeoTIFFs/Shapefiles right into _Google Drive_ (empty string will make saving to _Google Drive_'s root into folders `input`/`output`). `PATH_STORAGE` is used with the `PATH_DRIVE` variable only.\n",
        "\n",
        "`PATH_TEMP` is used to store intermediate GeoTIFFs while processing.\n",
        "\n",
        "`PATH_INPUT` is used as a source of GeoTIFFs (differs from _dataset_ directory in that it have **no masks**).\n",
        "\n",
        "`PATH_OUTPUT` is used to save images (for example, inference on a test subset).\n",
        "\n",
        "`PATH_MODELS` is used to save model weights for later inference.\n",
        "\n",
        "`PATH_DATASET` is a source of GeoTIFF **images** and **masks** for training and inference (for example, test subset).\n",
        "\n",
        "`PATH_RESOURCES` is used as a source of auxiliary files such as GeoJSON search area or Shapefile cutline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX5i8_qertA2"
      },
      "source": [
        "import os\n",
        "from os import path as osp\n",
        "\n",
        "\n",
        "PATH_STORAGE = osp.join('ods', 'soc')  # arbitrary subpath in Google Drive (if any)\n",
        "if 'PATH_DRIVE' in locals():\n",
        "    PREFIX_DRIVE = osp.join(osp.basename(PATH_DRIVE), 'MyDrive', PATH_STORAGE)\n",
        "else:\n",
        "    PREFIX_DRIVE = ''\n",
        "\n",
        "PATH_TEMP = osp.join('/', 'content', 'temp')\n",
        "PATH_INPUT = osp.join('/', 'content', PREFIX_DRIVE, 'input')\n",
        "PATH_OUTPUT = osp.join('/', 'content', PREFIX_DRIVE, 'output')\n",
        "PATH_MODELS = osp.join('/', 'content', PREFIX_DRIVE, 'models')\n",
        "PATH_DATASET = osp.join('/', 'content', PREFIX_DRIVE, 'dataset')\n",
        "PATH_OPENVINO = osp.join('/', 'content', PREFIX_DRIVE, 'vino')\n",
        "PATH_RESOURCES = osp.join('/', 'content', 'resources')\n",
        "\n",
        "print('\\n'.join((PATH_STORAGE, PATH_TEMP, PATH_INPUT, PATH_OUTPUT, PATH_MODELS,\n",
        "                 PATH_DATASET, PATH_OPENVINO, PATH_RESOURCES)))\n",
        "\n",
        "os.environ['PATH_OPENVINO'] = PATH_OPENVINO\n",
        "os.environ['PATH_TEMP'] = PATH_TEMP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jycHnaE3r-r9"
      },
      "source": [
        "# Functions\n",
        "\n",
        "Auxiliary functions (for example, drawing/plotting data)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-7u2AOLr3BK"
      },
      "source": [
        "import os\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def draw_one_row(*images, size=1024, output=None):\n",
        "    try:\n",
        "        size = size[:2]\n",
        "    except:\n",
        "        size = (size, size)\n",
        "    count = len(images)\n",
        "    figure, axes = plt.subplots(1, count, dpi=72,\n",
        "                                figsize=(size[0] / 72, size[1] / 72))\n",
        "    for i in range(count):\n",
        "        axes[i].imshow(images[i])\n",
        "    if output is not None:\n",
        "        try:\n",
        "            os.makedirs(osp.dirname(output), exist_ok=True)\n",
        "            plt.savefig(output)\n",
        "        except:\n",
        "            pass\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJrBtd0ZsHEH"
      },
      "source": [
        "# W&B\n",
        "\n",
        "An API token is required in order to authorize in WandB:\n",
        "https://wandb.ai/authorize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syrWdMRZsHfR"
      },
      "source": [
        "%pip install --quiet --upgrade wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxjoowHfseq7"
      },
      "source": [
        "import os\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "\n",
        "# ATTENTION: do not forget to set proper WandB token here (as string)\n",
        "if os.getenv('WANDB_API_KEY', None) is None:\n",
        "    os.environ['WANDB_API_KEY'] = getpass('https://wandb.ai/authorize :')\n",
        "# os.environ['WANDB_MODE'] = 'dryrun'  # 'offline' / do not sync immediately\n",
        "\n",
        "try:\n",
        "    import wandb\n",
        "    wandb.login()\n",
        "except:\n",
        "    wandb = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgR1hucn_9E2"
      },
      "source": [
        "WANDB_ENTITY = 'maritimeai'\n",
        "WANDB_PROJECT = 'sea-ice-segmentation'\n",
        "WANDB_GROUP = 'OpenVINO'\n",
        "WANDB_NAME = '/'.join(['OpenVINO', 'Baseline'])\n",
        "\n",
        "if 'wandb' in locals() and wandb is not None:\n",
        "    experiment = wandb.init(entity=WANDB_ENTITY,  # config=config,\n",
        "                            project=WANDB_PROJECT, group=WANDB_GROUP,\n",
        "                            name=WANDB_NAME, notes='OpenVINO debug pipeline')\n",
        "else:\n",
        "    experiment = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wehxX73u7ucl"
      },
      "source": [
        "artifacts_baseline = [\n",
        "    'Baseline.Fold1.2021-09-13-09-15-27:latest',\n",
        "    'Baseline.Fold2.2021-10-12-07-54-33:latest',\n",
        "    'Baseline.Fold3.2021-09-17-10-37-26:latest',\n",
        "    'Baseline.Fold4.2021-09-24-22-44-24:latest',\n",
        "    'Baseline.Fold5.2021-09-23-09-45-27:latest'\n",
        "]\n",
        "if experiment is not None:\n",
        "    artifacts = {}\n",
        "    for artifact_name in artifacts_baseline:\n",
        "        artifact = experiment.use_artifact(artifact_name)\n",
        "        artifacts[artifact_name] = {\n",
        "            'data': artifact,\n",
        "            'path': osp.abspath(artifact.download())\n",
        "        }\n",
        "\n",
        "    print(f\"Downloaded {len(artifacts)} artifacts\")\n",
        "    experiment.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xghxk3nhD4Ii"
      },
      "source": [
        "artifacts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAL40pBzD_Gb"
      },
      "source": [
        "%ls artifacts/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDNKVpaJsbDQ"
      },
      "source": [
        "# Data loading\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycFsnTmrs170"
      },
      "source": [
        "# Images/masks paths\n",
        "path_images_hh = osp.join(PATH_DATASET, 'images', 'hh')\n",
        "path_images_hv = osp.join(PATH_DATASET, 'images', 'hv')\n",
        "path_masks = osp.join(PATH_DATASET, 'masks', '2-class')\n",
        "\n",
        "items_images = set(os.listdir(path_images_hh))\n",
        "items_masks = set(os.listdir(path_masks))\n",
        "items_test = sorted(items_images - items_masks)\n",
        "dict(enumerate(items_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IugAUU1T6IZ"
      },
      "source": [
        "# ONNX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QakkMepUMiU"
      },
      "source": [
        "## Shapefile cutline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfo04zuBtBcR"
      },
      "source": [
        "!git clone https://github.com/MaritimeAI/resources.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yghtZDHmtF5u"
      },
      "source": [
        "> Cutline shape may also be checked with `ogrinfo` utility from _GDAL_ library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4WZXF2ktVye"
      },
      "source": [
        "FILE_SHAPEFILE = osp.join(PATH_RESOURCES, 'clustering', 'cutline',\n",
        "                          'Start_Ice_Map_UTMz40WGS84f_r.shp')\n",
        "\n",
        "try:\n",
        "    if osp.isfile(FILE_SHAPEFILE):\n",
        "        shape = osp.abspath(osp.realpath(FILE_SHAPEFILE))\n",
        "    else:\n",
        "        raise FileNotFoundError\n",
        "except (TypeError, FileNotFoundError) as e:\n",
        "    print(f\"Shapefile '{FILE_SHAPEFILE}' does not exist!\")\n",
        "    shape = None\n",
        "print(f\"Available shape is {shape}\")\n",
        "# !ogrinfo \"{shape}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aWMLwT6tAp3"
      },
      "source": [
        "## Inference and visualization (ONNX)\n",
        "\n",
        "Use vectorized cutline from repository to crop `NoData` area."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jezaC_oKtZWo"
      },
      "source": [
        "Inference part itself that does not depend on _PyTorch_ or any model code â just _ONNX_ exported model and _ONNX Runtime_.\n",
        "\n",
        "> HH + HV polarizations are being combined during inference, just like in `DatasetSAR` class.\n",
        "\n",
        "> _Python_'s garbage collector is being used intensively here, 'cause images are really large."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abh1Y19YE4Bx"
      },
      "source": [
        "%pip install --quiet onnxruntime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHHucJEDtgUm"
      },
      "source": [
        "import gc\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import onnxruntime\n",
        "\n",
        "from tempfile import TemporaryDirectory\n",
        "from time import time\n",
        "\n",
        "from osgeo import gdal\n",
        "\n",
        "PLOT = True\n",
        "INFERENCE_ONNX = False  # optionally avoid inferencing with ONNX Runtime\n",
        "\n",
        "time_inference_onnx = {}\n",
        "\n",
        "if INFERENCE_ONNX:\n",
        "    for artifact in artifacts:\n",
        "        session_ort = onnxruntime.InferenceSession(osp.join(artifacts[artifact]\\\n",
        "                                                            ['path'],\n",
        "                                                            'model.onnx'))\n",
        "        time_inference_onnx[artifact] = []\n",
        "        # Target directory for test inference\n",
        "        path_target = osp.join(PATH_TEMP, 'onnx', artifact)\n",
        "        os.makedirs(path_target, exist_ok=True)\n",
        "        # Batch size is supposed to be 1\n",
        "        for i, item_test in enumerate(items_test):\n",
        "            source = osp.join(path_images_hh, item_test)\n",
        "            target = osp.join(path_target, item_test)\n",
        "            with TemporaryDirectory() as path_temp:\n",
        "                temp = osp.join(path_temp, item_test)\n",
        "                gdal.Translate(temp, source,\n",
        "                            options=['-b', '1', '-colorinterp', 'gray',\n",
        "                                        '-co', 'COMPRESS=DEFLATE'])\n",
        "\n",
        "                # Input images must be 8-bit GeoTIFFs\n",
        "                image_hh = cv.imread(osp.join(path_images_hh, item_test),\n",
        "                                    cv.IMREAD_LOAD_GDAL)\n",
        "                image_hv = cv.imread(osp.join(path_images_hv, item_test),\n",
        "                                    cv.IMREAD_LOAD_GDAL)\n",
        "\n",
        "                # Make HH and HV sizes match (sizes mismatch should never happen)\n",
        "                # image_hv = cv.resize(image_hv, image_hh.shape[::-1],\n",
        "                #                      cv.INTER_NEAREST)\n",
        "                image = (np.dstack((image_hv, image_hh, image_hv)) /\n",
        "                         np.float32(255))\n",
        "                del image_hh, image_hv\n",
        "                gc.collect()\n",
        "\n",
        "                image = cv.resize(image, (1024, 1024), cv.INTER_LINEAR)\n",
        "                # Output image (GeoTIFF copy of image_hh)\n",
        "                dataset = gdal.Open(temp, gdal.GA_Update)\n",
        "                band = dataset.GetRasterBand(1)\n",
        "                h, w = band.ReadAsArray().shape\n",
        "\n",
        "                # Inference\n",
        "                time_start = time()\n",
        "                inputs_ort = {\n",
        "                    session_ort.get_inputs()[0].name: (np.moveaxis(image,\n",
        "                                                                   -1, 0)\\\n",
        "                                                       [None, ...])\n",
        "                }\n",
        "                outputs_ort = session_ort.run(None, inputs_ort)\n",
        "                time_stop = time()\n",
        "                # Log inference time\n",
        "                time_inference_onnx[artifact].append(time_stop - time_start)\n",
        "\n",
        "                # Process inference result into a mask\n",
        "                # WARNING: this resize part works just because there are 3 classes\n",
        "                mask = cv.resize(np.moveaxis(outputs_ort[0][0], 0, -1),\n",
        "                                (w, h), cv.INTER_NEAREST)\n",
        "                # mask[..., 2] *= 2  # change 'ice' class weight\n",
        "                mask = mask.argmax(-1).clip(0, 255).astype('uint8')\n",
        "                # Save the mask to GDAL dataset\n",
        "                band.WriteArray(mask)\n",
        "                dataset.FlushCache()\n",
        "                del band, dataset\n",
        "                gc.collect()\n",
        "\n",
        "                # Write mask as GeoTIFF (assume NoData value is always zero)\n",
        "                gdal.Warp(target, temp, dstNodata=0, xRes=40, yRes=40,\n",
        "                        cutlineDSName=f\"{shape}\",\n",
        "                        cropToCutline=(True if shape else False),\n",
        "                        creationOptions=['COMPRESS=DEFLATE'])\n",
        "                if PLOT:\n",
        "                    mask = cv.imread(target, cv.IMREAD_LOAD_GDAL)\n",
        "                    draw_one_row(cv.resize(image, (w, h), cv.INTER_LINEAR),\n",
        "                                 mask)\n",
        "                del image, mask\n",
        "            gc.collect()\n",
        "\n",
        "time_inference_onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_dARiJxnkJp"
      },
      "source": [
        "# OpenVINO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxYlXwTVAE4N"
      },
      "source": [
        "## Convert ONNX models to OpenVINO\n",
        "\n",
        "Model optimizer is being called via command-line: `mo --input_model <path/to/model.onnx> --output_dir <path/to/output>`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EMGQOO_a2Nl"
      },
      "source": [
        "models_openvino = {}\n",
        "\n",
        "try:\n",
        "    for artifact in artifacts:\n",
        "        models_openvino[artifact] = {}\n",
        "\n",
        "        # Source directory of the ONNX model\n",
        "        path_source = osp.abspath(osp.join(artifacts[artifact]['path'],\n",
        "                                           'model.onnx'))\n",
        "        models_openvino[artifact]['source'] = path_source\n",
        "        print(\"Model source:\", models_openvino[artifact]['source'])\n",
        "\n",
        "        # Target directory for the inference\n",
        "        path_target = osp.abspath(osp.join(PATH_TEMP, 'openvino',\n",
        "                                           artifact.split(':')[0]))\n",
        "        models_openvino[artifact]['target'] = path_target\n",
        "        os.makedirs(models_openvino[artifact]['target'], exist_ok=True)\n",
        "        print(\"Model target:\", models_openvino[artifact]['target'])\n",
        "\n",
        "        # Convert an ONNX model into OpenVINO IR (intermediate representation)\n",
        "        !mo --input_model {models_openvino[artifact]['source']} \\\n",
        "                      --output_dir {models_openvino[artifact]['target']} \\\n",
        "                      --framework onnx --batch 1 --data_type half \\\n",
        "                      --enable_concat_optimization\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "# models_openvino"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoknC3DAnsXh"
      },
      "source": [
        "Check out target paths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gax0Z-A9xLdo"
      },
      "source": [
        "for name_model in models_openvino:\n",
        "    print(models_openvino[name_model]['target'])\n",
        "    %ls {models_openvino[name_model]['target']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEDT1AI6IB7V"
      },
      "source": [
        "## Inference and visualization (OpenVINO)\n",
        "\n",
        "Cycle through all the models (from artifacts), cycling each model through the whole image set (150 HH+HV images)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McWUUobJA0zR"
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "from openvino.inference_engine import IECore, StatusCode\n",
        "\n",
        "\n",
        "IE_EXTENSION = None\n",
        "IE_DEVICE = 'CPU'\n",
        "IE_CONFIG = None\n",
        "\n",
        "PLOT = True\n",
        "\n",
        "time_inference_openvino = {}\n",
        "\n",
        "for artifact in artifacts:\n",
        "    ie = IECore()\n",
        "\n",
        "    if IE_EXTENSION:\n",
        "        ie.add_extension(IE_EXTENSION, IE_DEVICE)\n",
        "    if IE_CONFIG:\n",
        "        ie.set_config({'CONFIG_FILE': IE_CONFIG})\n",
        "\n",
        "    net = ie.read_network(model=osp.join(models_openvino[artifact]['target'],\n",
        "                                         'model.xml'))\n",
        "    # net = ie.read_network(model=osp.join(models_openvino[artifact]['source'])\\\n",
        "    #                       .replace('latest', 'v0'))\n",
        "\n",
        "    assert len(net.input_info) == 1, f\"Only single input topologies!\"\n",
        "    assert len(net.outputs) == 1, f\"Only single output topologies!\"\n",
        "\n",
        "    blob_input = next(iter(net.input_info))\n",
        "    # blob_output = next(iter(net.outputs))\n",
        "\n",
        "    # Configure Inference Engine (sync)\n",
        "    # net.input_info[blob_input].precision = 'U8'\n",
        "    # net.outputs[blob_output].precision = 'FP32'\n",
        "\n",
        "    num_inputs = len(items_images)  # dataset\n",
        "    # num_classes = max(net.outputs[blob_output].shape)\n",
        "    # print(f\"Classes = {num_classes}\")\n",
        "\n",
        "    net_exec = ie.load_network(network=net, device_name=IE_DEVICE,\n",
        "                               num_requests=num_inputs)\n",
        "\n",
        "    models_openvino[artifact]['network'] = net\n",
        "    models_openvino[artifact]['session'] = net_exec\n",
        "    models_openvino[artifact]['blob_input'] = blob_input\n",
        "    # models_openvino[artifact]['blob_output'] = blob_output\n",
        "\n",
        "for artifact in artifacts:\n",
        "    path_target = osp.join(models_openvino[artifact]['target'], 'output')\n",
        "    os.makedirs(path_target, exist_ok=True)\n",
        "    for item in items_images:\n",
        "        source = osp.join(path_images_hh, item)\n",
        "        target = osp.join(path_target, item)\n",
        "        with TemporaryDirectory() as path_temp:\n",
        "            temp = osp.join(path_temp, item)\n",
        "            gdal.Translate(temp, source,\n",
        "                        options=['-b', '1', '-colorinterp', 'gray',\n",
        "                                    '-co', 'COMPRESS=DEFLATE'])\n",
        "\n",
        "            # Input images must be 8-bit GeoTIFFs\n",
        "            image_hh = cv.imread(osp.join(path_images_hh, item),\n",
        "                                cv.IMREAD_LOAD_GDAL)\n",
        "            image_hv = cv.imread(osp.join(path_images_hv, item),\n",
        "                                cv.IMREAD_LOAD_GDAL)\n",
        "\n",
        "            # Make HH and HV sizes match (sizes mismatch should never happen)\n",
        "            # image_hv = cv.resize(image_hv, image_hh.shape[::-1], cv.INTER_NEAREST)\n",
        "            image = np.dstack((image_hv, image_hh, image_hv)) / np.float32(255)\n",
        "            del image_hh, image_hv\n",
        "            gc.collect()\n",
        "\n",
        "            _, _, h, w = (models_openvino[artifact]['network']\n",
        "                        .input_info[models_openvino[artifact]['blob_input']]\n",
        "                        .input_data.shape)\n",
        "            image = cv.resize(image, (w, h), cv.INTER_LINEAR)\n",
        "            image = image.transpose((2, 0, 1))  # HWC -> CHW\n",
        "            image = np.expand_dims(image, axis=0)  # CHW -> NCHW\n",
        "\n",
        "            # Output image (GeoTIFF copy of image_hh)\n",
        "            dataset = gdal.Open(temp, gdal.GA_Update)\n",
        "            band = dataset.GetRasterBand(1)\n",
        "            h, w = band.ReadAsArray().shape\n",
        "\n",
        "            # Inference\n",
        "            time_start = time()\n",
        "            result = (models_openvino[artifact]['session']\n",
        "                    .infer(inputs={\n",
        "                        models_openvino[artifact]['blob_input']: image\n",
        "                    }))\n",
        "            time_stop = time()\n",
        "            # Log inference time\n",
        "            times = time_inference_openvino.get('artifact', [])\n",
        "            time_inference_openvino[artifact] = times\n",
        "            time_inference_openvino[artifact].append(time_stop - time_start)\n",
        "\n",
        "            # Process inference result into a mask\n",
        "            # WARNING: this resize part works just because there are 3 classes\n",
        "            mask_raw = np.moveaxis(result['output'][0], 0, -1)\n",
        "            mask = cv.resize(mask_raw, (w, h), cv.INTER_NEAREST)\n",
        "            # mask[..., 2] *= 2  # change 'ice' class weight\n",
        "            mask = mask.argmax(-1).clip(0, 255).astype('uint8')\n",
        "            # Save the mask to GDAL dataset\n",
        "            band.WriteArray(mask)\n",
        "            dataset.FlushCache()\n",
        "            del band, dataset\n",
        "            gc.collect()\n",
        "\n",
        "            # Write mask as GeoTIFF (assume NoData value is always zero)\n",
        "            gdal.Warp(target, temp, dstNodata=0, xRes=40, yRes=40,\n",
        "                    cutlineDSName=f\"{shape}\",\n",
        "                    cropToCutline=(True if shape else False),\n",
        "                    creationOptions=['COMPRESS=DEFLATE'])\n",
        "            if PLOT:\n",
        "                mask = cv.imread(target, cv.IMREAD_LOAD_GDAL)\n",
        "                # print(f\"Nodata: min = {mask_raw[..., 0].min()},\",\n",
        "                #       f\"max = {mask_raw[..., 0].max()}\")\n",
        "                # print(f\"Water: min = {mask_raw[..., 1].min()},\",\n",
        "                #       f\"max = {mask_raw[..., 1].max()}\")\n",
        "                # print(f\"Ice: min = {mask_raw[..., 2].min()},\",\n",
        "                #       f\"max = {mask_raw[..., 2].max()}\")\n",
        "                draw_one_row(cv.resize(image[0].transpose((1, 2, 0)),\n",
        "                                    (w, h), cv.INTER_LINEAR), mask)\n",
        "            del image, mask\n",
        "        gc.collect()\n",
        "\n",
        "    models_openvino[artifact]['times'] = time_inference_openvino['artifact']\n",
        "    break\n",
        "\n",
        "time_inference_openvino"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNY8s8fxGX3v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}