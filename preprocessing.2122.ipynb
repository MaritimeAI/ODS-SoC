{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing.2122.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY_S9jH7fdE-"
      },
      "source": [
        "# Check container OS version (for correct UbuntuGIS package version)\n",
        "!lsb_release -a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4AZorcKfDAJ"
      },
      "source": [
        "# Dark magic happens here: installing dependencies for GDAL 3.0.4\n",
        "# build process via APT and install GDAL itself via PyPI\n",
        "!time (add-apt-repository -y ppa:ubuntugis/ubuntugis-unstable && \\\n",
        " apt install python3-gdal=3.0.4+dfsg-1~bionic0 && \\\n",
        " apt purge --autoremove python3-gdal && \\\n",
        " pip install gdal==3.0.4 && \\\n",
        " apt install gdal-bin=3.0.4+dfsg-1~bionic0)\n",
        "\n",
        "from osgeo import gdal; print(f\"\\nGDAL version {(gdal.__version__)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OC9fAJYfqpH"
      },
      "source": [
        "# Google Drive\n",
        "\n",
        "from os import path as osp\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "PATH_DRIVE = osp.join('/', 'content', 'drive')\n",
        "\n",
        "# Do not mount if it is already attached\n",
        "if not osp.exists(PATH_DRIVE):\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    drive.mount(PATH_DRIVE)\n",
        "else:\n",
        "    print(\"Google Drive has been already mounted!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S43o_kEQfvVS"
      },
      "source": [
        "from os import path as osp\n",
        "\n",
        "PATH_STORAGE = osp.join('ods', 'soc')  # arbitrary subpath in Google Drive\n",
        "if 'PATH_DRIVE' in locals():\n",
        "    PREFIX_DRIVE = osp.join(osp.basename(PATH_DRIVE), 'MyDrive', PATH_STORAGE)\n",
        "else:\n",
        "    PREFIX_DRIVE = ''\n",
        "\n",
        "PATH_TEMP = osp.join('/', 'content', 'temp')\n",
        "PATH_INPUT = osp.join('/', 'content', PREFIX_DRIVE, 'input')\n",
        "PATH_OUTPUT = osp.join('/', 'content', PREFIX_DRIVE, 'output')\n",
        "PATH_RESOURCES = osp.join('/', 'content', 'resources')\n",
        "PATH_SNAPSHOTS = osp.join('/', 'content', 'snapshots')\n",
        "# Uncomment to save the source Copernicus archives in Google Drive (extra space)\n",
        "# PATH_SNAPSHOTS = osp.join('/', 'content', PREFIX_DRIVE, 'snapshots')\n",
        "\n",
        "print('\\n'.join((PATH_STORAGE, PATH_TEMP, PATH_INPUT, PATH_OUTPUT,\n",
        "                 PATH_RESOURCES, PATH_SNAPSHOTS)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE8E6OeAWYvv"
      },
      "source": [
        "!pip install git+https://github.com/MaritimeAI/copernicus\n",
        "!git clone https://github.com/MaritimeAI/resources.git {PATH_RESOURCES}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO95SumHgRdg"
      },
      "source": [
        "FILE_SHAPEFILE = osp.join(PATH_RESOURCES, 'clustering', 'cutline',\n",
        "                          'Start_Ice_Map_UTMz40WGS84f_r.shp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb93K9z4T4sg"
      },
      "source": [
        "SPLIT = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbyyPl8YPiQ"
      },
      "source": [
        "%ls {PATH_INPUT}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO5bVCh2f5mn"
      },
      "source": [
        "# %%time\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "from getpass import getpass\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from copernicus import Config\n",
        "from copernicus import DataHub\n",
        "from copernicus import download\n",
        "from copernicus import Polygons\n",
        "\n",
        "\n",
        "FORMAT_COPERNICUS_DATETIME = '%Y-%m-%dT%H:%M:%S.%f'\n",
        "PATH_AREA_SEARCH = osp.join('resources', 'copernicus',\n",
        "                            'areas', 'pechora.geojson')\n",
        "\n",
        "if os.getenv('COPERNICUS_USERNAME', None) is None:\n",
        "    os.environ['COPERNICUS_USERNAME'] = getpass('Username:')\n",
        "if os.getenv('COPERNICUS_PASSWORD', None) is None:\n",
        "    os.environ['COPERNICUS_PASSWORD'] = getpass('Password:')\n",
        "\n",
        "config = Config()\n",
        "config.username = os.environ['COPERNICUS_USERNAME']  # <-- set Copernicus Open Access Hub username here\n",
        "config.password = os.environ['COPERNICUS_PASSWORD']  # <-- set Copernicus Open Access Hub password here\n",
        "\n",
        "data_hub = DataHub(config)\n",
        "\n",
        "area = json.load(open(PATH_AREA_SEARCH))\n",
        "search = area['features'][0]['properties'].copy()\n",
        "\n",
        "# Uncomment to search snapshots for specific date\n",
        "# now = datetime.now().replace(month=5, day=4, hour=0, minute=0,\n",
        "#                              second=0, microsecond=0)\n",
        "now = datetime.now()\n",
        "# day = timedelta(hours=23, minutes=59,\n",
        "#                 seconds=59, microseconds=999999)\n",
        "\n",
        "date_start = datetime(2021, 10, 1).strftime(FORMAT_COPERNICUS_DATETIME)[:-3] + 'Z'\n",
        "date_stop = now.strftime(FORMAT_COPERNICUS_DATETIME)[:-3] + 'Z'\n",
        "\n",
        "# Update time range for yesterday\n",
        "del search['filenames']\n",
        "search.update({\n",
        "    'start': 0,\n",
        "    'platformName': 'Sentinel-1',\n",
        "    'productType': 'GRD',\n",
        "    'beginPosition': f\"[{date_start} TO {date_stop}]\",\n",
        "    # 'beginPosition': f\"[NOW-2DAYS TO NOW]\",\n",
        "})\n",
        "# print(f\"DEBUG: search = {search}\")\n",
        "\n",
        "polygon, properties = Polygons.read_geojson(PATH_AREA_SEARCH)\n",
        "snapshots = data_hub.search(search, area=polygon)\n",
        "# print(f\"DEBUG: snapshots = {snapshots}\")\n",
        "\n",
        "config.output = PATH_SNAPSHOTS\n",
        "\n",
        "print('Snapshots count =', len(snapshots))\n",
        "# for i, snapshot in enumerate(snapshots):\n",
        "    # print(f\"{i:03d}\", snapshot.__dict__)\n",
        "    # download(snapshot.link, config)\n",
        "    # print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR_Z_-7YeQvO"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "frame_snapshots = pd.DataFrame({k: [s.__dict__[k] for s in snapshots] \\\n",
        "                                for k in snapshots[0].__dict__})\\\n",
        "                                .sort_values(['begin_position'])\n",
        "\n",
        "pd.set_option('display.max_rows', frame_snapshots.shape[0] + 1)\n",
        "\n",
        "frame_snapshots['polygon'] = (frame_snapshots['polygon']\n",
        "                              .apply(lambda x: x.wkt if type(x) is not str else x))\n",
        "frame_snapshots['week'] = (frame_snapshots['begin_position']\n",
        "                           .apply(lambda x: x.isocalendar()[1]))\n",
        "frame_snapshots['split'] = frame_snapshots['week'].apply(lambda x: x % 5 + 1)\n",
        "\n",
        "frame_snapshots = frame_snapshots.set_index('uuid')\n",
        "\n",
        "frame_snapshots"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGdx1DlJjmSG"
      },
      "source": [
        "frame_snapshots_split = frame_snapshots[frame_snapshots['split'] == SPLIT]\n",
        "\n",
        "index = 0\n",
        "for uuid, snapshot in frame_snapshots_split.iterrows():\n",
        "    index += 1\n",
        "    print(f\"{index:03d}\", snapshot['title'])\n",
        "    download(snapshot['link'], config)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgkF4lqSf40V"
      },
      "source": [
        "!pip uninstall -y maritimeai\n",
        "!pip install git+https://github.com/MaritimeAI/maritimeai@master#egg=maritimeai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMbY4mKegHKs"
      },
      "source": [
        "# %%time\n",
        "\n",
        "from glob import glob\n",
        "from zipfile import BadZipFile\n",
        "\n",
        "from maritimeai import process_sentinel1\n",
        "\n",
        "filenames = []\n",
        "\n",
        "if osp.isdir(PATH_SNAPSHOTS):\n",
        "    for filename in glob(osp.join(PATH_SNAPSHOTS, '*.zip')):\n",
        "        try:\n",
        "            print(f\"Processing {filename}...\")\n",
        "            filenames.extend(process_sentinel1(filename, PATH_TEMP,\n",
        "                                               area='default',\n",
        "                                               shapes=[FILE_SHAPEFILE],\n",
        "                                               negative=False))\n",
        "        except BadZipFile:\n",
        "            print(f\"ERROR: {filename} is damaged!\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Path '{PATH_SNAPSHOTS}' must exist!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYLNTW1Hdqd7"
      },
      "source": [
        "filenames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv0A1E-V9eWN"
      },
      "source": [
        "from glob import glob\n",
        "\n",
        "import cv2 as cv\n",
        "\n",
        "\n",
        "frame_snapshots_split['coverage'] = 0.0\n",
        "\n",
        "for i, row in frame_snapshots_split.iterrows():\n",
        "    try:\n",
        "        path = glob(osp.join(PATH_TEMP, 'default*', 'hh',\n",
        "                             f\"{row['title']}.tiff\"))[0]\n",
        "        coverage = (cv.imread(path, cv.IMREAD_LOAD_GDAL) > 0).mean()\n",
        "        frame_snapshots_split.loc[i, 'coverage'] = coverage\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "frame_snapshots_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B0dKAA7_EnN"
      },
      "source": [
        "THRESHOLD_COVERAGE = 0.1  # ratio 0.08 gives small pieces"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HujEGh57ifBZ"
      },
      "source": [
        "from glob import glob\n",
        "from shutil import copy2 as copy\n",
        "\n",
        "import cv2 as cv\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "COPY = True\n",
        "\n",
        "index_threshold = frame_snapshots_split['coverage'] >= THRESHOLD_COVERAGE\n",
        "frame_threshold = frame_snapshots_split[index_threshold]\n",
        "\n",
        "for i, row in frame_threshold.iterrows():\n",
        "    try:\n",
        "        filename = glob(osp.join(PATH_TEMP, 'default*', 'negative',\n",
        "                                f\"{row['title']}.tiff\"))[0]\n",
        "        image = cv.imread(filename, cv.IMREAD_LOAD_GDAL)\n",
        "        print(osp.basename(filename), row['coverage'])\n",
        "        if COPY:\n",
        "            path_source = f\"{osp.join(PATH_SNAPSHOTS, row['title'])}.zip\"\n",
        "            path_target = path_source.replace(PATH_SNAPSHOTS,\n",
        "                                              osp.join(PATH_INPUT, 'snapshots'))\n",
        "            os.makedirs(osp.dirname(path_target), exist_ok=True)\n",
        "            copy(path_source, path_target)\n",
        "            print(f\"{path_source} -> {path_target}\")\n",
        "            for path_source in filenames:\n",
        "                if osp.splitext(osp.basename(path_source))[0] == row['title']:\n",
        "                    path_target = path_source.replace(PATH_TEMP, PATH_INPUT)\n",
        "                    os.makedirs(osp.dirname(path_target), exist_ok=True)\n",
        "                    copy(path_source, path_target)\n",
        "                    print(f\"{path_source} -> {path_target}\")\n",
        "\n",
        "        plt.figure(figsize=(15, 15))\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))\n",
        "        plt.show()\n",
        "    except KeyboardInterrupt:\n",
        "        break\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq27v5W_NSVn"
      },
      "source": [
        "path_snapshots_db = osp.join(PATH_INPUT, f\"snapshots.{SPLIT}.csv\")\n",
        "\n",
        "try:\n",
        "    frame_snapshots_read = pd.read_csv(path_snapshots_db, index_col=0)\n",
        "except:\n",
        "    raise\n",
        "    frame_snapshots_read = pd.DataFrame([], columns=frame_snapshots_split.columns)\n",
        "\n",
        "frame_snapshots_split_ = pd.concat([frame_snapshots_read, frame_snapshots_split])\n",
        "frame_snapshots_split_ = frame_snapshots_split_[~frame_snapshots_split_.index\\\n",
        "                                                .duplicated(keep='last')]\n",
        "frame_snapshots_split_.to_csv(path_snapshots_db)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdAhpxh9kG_X"
      },
      "source": [
        "frame_unthreshold = frame_snapshots_split[~index_threshold]\n",
        "\n",
        "for i, row in frame_unthreshold.iterrows():\n",
        "    try:\n",
        "        filename = glob(osp.join(PATH_TEMP, 'default*', 'hh',\n",
        "                                f\"{row['title']}.tiff\"))[0]\n",
        "        image = cv.imread(filename, cv.IMREAD_LOAD_GDAL)\n",
        "        print(osp.basename(filename), row['coverage'])\n",
        "\n",
        "        plt.figure(figsize=(15, 15))\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))\n",
        "        plt.show()\n",
        "    except KeyboardInterrupt:\n",
        "        break\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h94qwKCvG_vV"
      },
      "source": [
        "%cat {path_snapshots_db}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNg98e-wNzc0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}